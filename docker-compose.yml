# --- DEFINE THE BASE SERVICE TEMPLATE ---
# We no longer need x-common-settings, as all parameters are passed via argparse
x-base-service-def: &base  
  build:
      context: . # Path to the Dockerfile (current directory)
      dockerfile: Dockerfile
      args:
        USER_ID: ${UID:-1000}
        GROUP_ID: ${GID:-1000}
  # --- SETTINGS FROM YOUR OTHER FILE ---
  # This is the magic key to keep containers alive and attachable
  tty: true 
  # This prevents crashes by giving PyTorch more shared memory
  shm_size: '128g'
  # This ensures files you create in volumes are owned by you, not root
  user: "${UID:-1000}:${GID:-1000}"
  
  volumes:
    - /data/siedel/trained_models/latent-diffusion/:/app/models/ldm/cin256
    - ./configs:/app/configs:ro
    - ./data/IN100.txt:/app/data/IN100.txt:ro
    - ./data/imagenet_class_index.json:/app/data/imagenet_class_index.json:ro
    - /data/siedel/datasets/ImageNet-100-synthetic:/app/outputs
    # --- Mount the script so you can edit it live ---
    - ./sample_conditional.py:/app/sample_conditional.py:ro
  runtime: nvidia

services:
  sampler-0:
    <<: *base 
    environment:
      NVIDIA_VISIBLE_DEVICES: "0"

  sampler-1:
    <<: *base
    environment:
      NVIDIA_VISIBLE_DEVICES: "1"

  sampler-2:
    <<: *base
    environment:
      NVIDIA_VISIBLE_DEVICES: "2"

  sampler-3:
    <<: *base
    environment:
      NVIDIA_VISIBLE_DEVICES: "3"

  sampler-4:
    <<: *base
    environment:
      NVIDIA_VISIBLE_DEVICES: "4"

  sampler-5:
    <<: *base
    environment:
      NVIDIA_VISIBLE_DEVICES: "5"

  sampler-6:
    <<: *base
    environment:
      NVIDIA_VISIBLE_DEVICES: "6"

  sampler-7:
    <<: *base
    environment:
      NVIDIA_VISIBLE_DEVICES: "7"